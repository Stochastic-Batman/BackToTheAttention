{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inference\n",
    "\n",
    "You **must** run `data_and_training.ipynb` before running this notebook. I will skip blah-blah and start with imports and logger config:"
   ],
   "id": "947482adf343d67a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:20.887970Z",
     "start_time": "2025-12-21T14:45:16.966012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%d/%m/%Y %H:%M:%S')\n",
    "logger = logging.getLogger(\"BackToThePredictLogger (Predict)\")"
   ],
   "id": "3a51057def8a78b6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These are from `DeTention.py` and/or `data_and_training.ipynb`, but they need to be present here as well. Just ignore it; you are already familiar with these classes:",
   "id": "7eace8b49895ecdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:20.916446Z",
     "start_time": "2025-12-21T14:45:20.898665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, dim: int, base: float = 10000.0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(start=0, end=dim, step=2, dtype=torch.float32) / dim))\n",
    "        self.register_buffer(name=\"inv_freq\", tensor=inv_freq, persistent=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, seq_len: int) -> torch.Tensor:\n",
    "        positions = torch.arange(0, seq_len, device=x.device, dtype=self.inv_freq.dtype)\n",
    "        angles = positions[:, None] * self.inv_freq[None, :]\n",
    "        sin, cos = torch.sin(angles), torch.cos(angles)\n",
    "        sin = sin.unsqueeze(0)\n",
    "        cos = cos.unsqueeze(0)\n",
    "        x1 = x[..., : self.dim // 2]\n",
    "        x2 = x[..., self.dim // 2:]\n",
    "        rotated_x1 = x1 * cos - x2 * sin\n",
    "        rotated_x2 = x1 * sin + x2 * cos\n",
    "        return torch.cat([rotated_x1, rotated_x2], dim=-1)\n",
    "\n",
    "\n",
    "class DeTentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, ff_hidden_size: int = 256, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_hidden_size = ff_hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.rope = RoPE(dim=d_model, base=10000.0)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=n_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, ff_hidden_size), nn.GLU(dim=-1), nn.Dropout(dropout), nn.Linear(ff_hidden_size // 2, d_model))\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        q, k = self.rope(x, seq_len=x.shape[1]), self.rope(x, seq_len=x.shape[1])\n",
    "        attn_output, _ = self.attention(query=q, key=k, value=x, need_weights=False)\n",
    "        x = self.dropout_layer(attn_output) + residual\n",
    "        residual = x\n",
    "        x = self.ff(self.norm2(x))\n",
    "        x = self.dropout_layer(x) + residual\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeTention(nn.Module):\n",
    "    def __init__(self, seq_len: int = 30, d_model: int = 64, n_heads: int = 4, n_layers: int = 2, ff_hidden_size: int = 256, dropout: float = 0.2, use_avg_pool: bool = True):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.use_avg_pool = use_avg_pool\n",
    "        self.input_proj = nn.Linear(1, d_model)\n",
    "        self.DeTention_blocks = nn.ModuleList([DeTentionBlock(d_model=d_model, n_heads=n_heads, ff_hidden_size=ff_hidden_size, dropout=dropout) for i in range(n_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.output_head = nn.Linear(d_model, 1)\n",
    "        if use_avg_pool:\n",
    "            self.pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_proj(x)\n",
    "        for block in self.DeTention_blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.pool(x.transpose(1, 2)).squeeze(-1) if self.use_avg_pool else x[:, -1, :]\n",
    "        x = self.output_head(x)\n",
    "        return x.squeeze(dim=-1)\n",
    "\n",
    "\n",
    "def save_model(model: DeTention, path: str = \"models/DeTention.pth\") -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save({ 'state_dict': model.state_dict(), 'config': { 'seq_len': model.seq_len, 'd_model': model.d_model, 'use_avg_pool': model.use_avg_pool } }, path)\n",
    "\n",
    "\n",
    "def load_model(path: str = \"models/DeTention.pth\", **model_kwargs) -> DeTention:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'), weights_only=True)\n",
    "    config = checkpoint.get('config', {})\n",
    "    config.update(model_kwargs)\n",
    "    model = DeTention(**config)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model"
   ],
   "id": "cef983d67a19f7c4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define a method to get the most recent data with dates:",
   "id": "c874a24efa061a33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:20.929590Z",
     "start_time": "2025-12-21T14:45:20.924401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_recent_data(ticker: str, period: str = \"3y\") -> tuple[np.ndarray, list]:\n",
    "    data = yf.Ticker(ticker)\n",
    "    df = data.history(period=period)\n",
    "    df.drop(columns=[\"Dividends\", \"Stock Splits\"], inplace=True, errors='ignore')\n",
    "    close_prices = df['Close'].values.reshape(-1, 1)\n",
    "    dates = df.index.tolist()\n",
    "    return close_prices, dates"
   ],
   "id": "b3062bbefebe1919",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test the model by predicting today's price and comparing it with the actual price:",
   "id": "94281f30154cd9d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:20.946592Z",
     "start_time": "2025-12-21T14:45:20.939256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_prediction(model: DeTention, scaler: MinMaxScaler, ticker: str = \"PINS\", L: int = 30, period: str = \"3y\"):\n",
    "    logger.info(\"TESTING MODEL ON RECENT DATA\")\n",
    "\n",
    "    series, dates = get_recent_data(ticker, period=period)\n",
    "\n",
    "    if len(series) < L + 1:\n",
    "        raise ValueError(f\"Not enough data points ({len(series)}) for lookback {L} + 1 for testing\")\n",
    "\n",
    "    # use the last L + 1 points: L for input, 1 for actual target\n",
    "    test_window = series[-(L + 1):-1]  # last L days (excluding most recent)\n",
    "    actual_price = series[-1, 0]  # most recent day (today's actual close)\n",
    "    actual_date = dates[-1]\n",
    "\n",
    "    test_scaled = scaler.transform(test_window)\n",
    "    input_tensor = torch.tensor(test_scaled, dtype=torch.float32).unsqueeze(0)  # (1, L, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scaled_pred = model(input_tensor).item()\n",
    "\n",
    "    predicted_price = scaler.inverse_transform([[scaled_pred]])[0][0]\n",
    "    error = abs(predicted_price - actual_price)\n",
    "    error_pct = (error / actual_price) * 100\n",
    "\n",
    "    logger.info(f\"Date: {actual_date.strftime('%Y-%m-%d')}\")\n",
    "    logger.info(f\"Actual closing price: ${actual_price:.2f}\")\n",
    "    logger.info(f\"Predicted price: ${predicted_price:.2f}\")\n",
    "    logger.info(f\"Absolute error: ${error:.2f}\")\n",
    "    logger.info(f\"Percentage error: {error_pct:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        'date': actual_date,\n",
    "        'actual': actual_price,\n",
    "        'predicted': predicted_price,\n",
    "        'error': error,\n",
    "        'error_pct': error_pct\n",
    "    }"
   ],
   "id": "fa1b6a17ee46ef3b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Obviously, I also need a method to predict the price for the next day simply:",
   "id": "2407e3532cfacfe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:20.960924Z",
     "start_time": "2025-12-21T14:45:20.955534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_next_day(model: DeTention, scaler: MinMaxScaler, ticker: str = \"PINS\", L: int = 30, period: str = \"3y\"):\n",
    "    logger.info(\"PREDICTING NEXT TRADING DAY\")\n",
    "\n",
    "    series, dates = get_recent_data(ticker, period=period)\n",
    "\n",
    "    if len(series) < L:\n",
    "        raise ValueError(f\"Not enough data points ({len(series)}) for lookback {L}\")\n",
    "\n",
    "    # use the most recent L days\n",
    "    recent_window = series[-L:]\n",
    "    last_date = dates[-1]\n",
    "    input_tensor = torch.tensor(scaler.transform(recent_window), dtype=torch.float32).unsqueeze(0)  # (1, L, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scaled_pred = model(input_tensor).item()\n",
    "\n",
    "    pred = scaler.inverse_transform([[scaled_pred]])[0][0]\n",
    "\n",
    "    logger.info(f\"Last trading day: {last_date.strftime('%Y-%m-%d')}\")\n",
    "    logger.info(f\"Last closing price: ${series[-1, 0]:.2f}\")\n",
    "    logger.info(f\"Predicted next-day closing price: ${pred:.2f}\")\n",
    "\n",
    "    return pred"
   ],
   "id": "c996c4ce7fea2cf0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameters:",
   "id": "6c20522825f4987c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:20.972753Z",
     "start_time": "2025-12-21T14:45:20.968853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"models/DeTention.pth\"\n",
    "scaler_path = \"models/scaler.pkl\"\n",
    "ticker = \"PINS\"\n",
    "L = 30\n",
    "period = \"3y\"\n",
    "test = True\n",
    "predict = True\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "\n",
    "if not os.path.exists(scaler_path):\n",
    "    raise FileNotFoundError(f\"Scaler not found: {scaler_path}\")"
   ],
   "id": "5f229065aac3995",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Time for inference!",
   "id": "197f75ce323c23a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:45:25.122202Z",
     "start_time": "2025-12-21T14:45:20.979996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Loading model from %s\", model_path)\n",
    "model = load_model(model_path)\n",
    "model.eval()\n",
    "\n",
    "logger.info(\"Loading scaler from %s\", scaler_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "if test:\n",
    "    test_results = test_prediction(model, scaler, ticker=ticker, L=L, period=period)\n",
    "    logger.info(\"TEST RESULTS FOR %s\", ticker)\n",
    "    logger.info(\"Date: %s\", test_results['date'].strftime('%Y-%m-%d'))\n",
    "    logger.info(\"Actual Price: $%.3f\", test_results['actual'])\n",
    "    logger.info(\"Predicted Price: $%.3f\", test_results['predicted'])\n",
    "    logger.info(\"Error: $%.3f (%.2f%%)\", test_results['error'], test_results['error_pct'])\n",
    "\n",
    "if predict:\n",
    "    next_price = predict_next_day(model, scaler, ticker=ticker, L=L, period=period)\n",
    "    logger.info(\"NEXT-DAY PREDICTION FOR %s\", ticker)\n",
    "    logger.info(\"Predicted Closing Price: $%.3f\", next_price)"
   ],
   "id": "1880d266bb1f3625",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/2025 18:45:20 - BackToThePredictLogger (Predict) - INFO - Loading model from models/DeTention.pth\n",
      "21/12/2025 18:45:20 - BackToThePredictLogger (Predict) - INFO - Loading scaler from models/scaler.pkl\n",
      "21/12/2025 18:45:20 - BackToThePredictLogger (Predict) - INFO - TESTING MODEL ON RECENT DATA\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Date: 2025-12-19\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Actual closing price: $26.08\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Predicted price: $25.95\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Absolute error: $0.13\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Percentage error: 0.51%\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - TEST RESULTS FOR PINS\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Date: 2025-12-19\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Actual Price: $26.080\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Predicted Price: $25.947\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - Error: $0.133 (0.51%)\n",
      "21/12/2025 18:45:24 - BackToThePredictLogger (Predict) - INFO - PREDICTING NEXT TRADING DAY\n",
      "21/12/2025 18:45:25 - BackToThePredictLogger (Predict) - INFO - Last trading day: 2025-12-19\n",
      "21/12/2025 18:45:25 - BackToThePredictLogger (Predict) - INFO - Last closing price: $26.08\n",
      "21/12/2025 18:45:25 - BackToThePredictLogger (Predict) - INFO - Predicted next-day closing price: $25.92\n",
      "21/12/2025 18:45:25 - BackToThePredictLogger (Predict) - INFO - NEXT-DAY PREDICTION FOR PINS\n",
      "21/12/2025 18:45:25 - BackToThePredictLogger (Predict) - INFO - Predicted Closing Price: $25.924\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As the stock data gets updated each and every day, the output will not be the same (plus I did not make the result reproducible; for `DataLoader`, that's a lot of ugly work!), but here is an output from my run:\n",
    "\n",
    "```bash\n",
    "Loading model from models/DeTention.pth\n",
    "Loading scaler from models/scaler.pkl\n",
    "TESTING MODEL ON RECENT DATA\n",
    "Date: 2025-12-19\n",
    "Actual closing price: $26.08\n",
    "Predicted price: $25.95\n",
    "Absolute error: $0.13\n",
    "Percentage error: 0.51%\n",
    "TEST RESULTS FOR PINS\n",
    "Date: 2025-12-19\n",
    "Actual Price: $26.080\n",
    "Predicted Price: $25.947\n",
    "Error: $0.133 (0.51%)\n",
    "PREDICTING NEXT TRADING DAY\n",
    "Last trading day: 2025-12-19\n",
    "Last closing price: $26.08\n",
    "Predicted next-day closing price: $25.92\n",
    "NEXT-DAY PREDICTION FOR PINS\n",
    "Predicted Closing Price: $25.92\n",
    "```\n",
    "\n",
    "So the results look great from my side! Though the error might not be tolerable for trading firms, that's why they hire quants and why I am not one of them."
   ],
   "id": "255088c6674d496e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
